-- POSTGRESQL INDEXING PERFORMANCE ANALYSIS

\c health_iot_benchmark;

-- Enable timing
\timing on

-- 1. INDEXING PERFORMANCE ANALYSIS
-- ============================================

DO $$
DECLARE
    analysis_start TIMESTAMPTZ;
    analysis_end TIMESTAMPTZ;
    total_indexes INTEGER;
    total_index_size_mb NUMERIC;
BEGIN
    RAISE NOTICE '============================================';
    RAISE NOTICE 'POSTGRESQL INDEXING PERFORMANCE ANALYSIS';
    RAISE NOTICE '============================================';
    
    analysis_start := clock_timestamp();
    
    -- Create indexing performance results table
    DROP TABLE IF EXISTS indexing_performance_results;
    CREATE TABLE indexing_performance_results (
        analysis_id SERIAL PRIMARY KEY,
        analysis_timestamp TIMESTAMPTZ DEFAULT NOW(),
        test_scenario VARCHAR(100),
        table_name VARCHAR(100),
        index_name VARCHAR(100),
        index_type VARCHAR(50),
        index_columns VARCHAR(500),
        index_size_mb NUMERIC(12,2),
        query_execution_time_ms NUMERIC(12,3),
        index_scan_time_ms NUMERIC(12,3),
        seq_scan_time_ms NUMERIC(12,3),
        performance_improvement NUMERIC(8,2),
        rows_returned BIGINT,
        index_scans BIGINT,
        index_size_updates BIGINT,
        is_used_regularly BOOLEAN,
        selectivity NUMERIC(8,4),
        maintenance_overhead_ms NUMERIC(12,3),
        recommendations TEXT,
        execution_plan JSONB
    );
    
    -- Get current index statistics
    SELECT 
        COUNT(*),
        SUM(pg_relation_size(indexrelid) / (1024.0 * 1024.0))
    INTO total_indexes, total_index_size_mb
    FROM pg_stat_user_indexes
    WHERE schemaname = 'public';
    
    RAISE NOTICE 'Current Index Status:';
    RAISE NOTICE '  Total indexes: %', total_indexes;
    RAISE NOTICE '  Total index size: % MB', ROUND(total_index_size_mb, 2);
    
    -- 2. EXISTING INDEX ANALYSIS
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 1: EXISTING INDEX ANALYSIS';
    RAISE NOTICE '----------------------------------';
    
    -- Analyze existing indexes
    WITH index_stats AS (
        SELECT 
            schemaname,
            tablename,
            indexrelname,
            idx_scan,
            idx_tup_read,
            idx_tup_fetch,
            pg_relation_size(schemaname || '.' || indexrelname) as index_size
        FROM pg_stat_user_indexes
        WHERE schemaname = 'public'
    ),
    table_stats AS (
        SELECT 
            schemaname,
            relname,
            seq_scan,
            seq_tup_read
        FROM pg_stat_user_tables
        WHERE schemaname = 'public'
    )
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, index_name, 
        index_size_mb, index_scans, is_used_regularly
    )
    SELECT 
        'existing_index_analysis',
        i.tablename,
        i.indexrelname,
        ROUND(i.index_size / (1024.0 * 1024.0), 2),
        i.idx_scan,
        i.idx_scan > 100  -- Consider regularly used if scanned > 100 times
    FROM index_stats i
    LEFT JOIN table_stats t ON i.schemaname = t.schemaname 
        AND i.tablename = t.relname
    ORDER BY i.index_size DESC;
    
    -- Display unused indexes
    RAISE NOTICE 'Potentially Unused Indexes (size > 10MB, scans < 10):';
    FOR rec IN 
        SELECT 
            table_name,
            index_name,
            ROUND(index_size_mb, 2) as size_mb,
            index_scans
        FROM indexing_performance_results
        WHERE test_scenario = 'existing_index_analysis'
          AND index_size_mb > 10
          AND index_scans < 10
        ORDER BY index_size_mb DESC
    LOOP
        RAISE NOTICE '  %.%: % MB, scans: %',
            rec.table_name, rec.index_name, rec.size_mb, rec.index_scans;
    END LOOP;
    
    -- 3. INDEX EFFECTIVENESS TESTING
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 2: INDEX EFFECTIVENESS TESTING';
    RAISE NOTICE '--------------------------------------';
    
    -- Test 1: Single column index performance
    RAISE NOTICE 'Test 1: Single Column Indexes';
    
    -- Test patient_id index
    PERFORM test_index_performance(
        'patient_vitals',
        'patient_id',
        'SELECT * FROM patient_vitals WHERE patient_id = ''PATIENT_00001''',
        'single_column_patient_id'
    );
    
    -- Test vital_type index
    PERFORM test_index_performance(
        'patient_vitals',
        'vital_type',
        'SELECT * FROM patient_vitals WHERE vital_type = ''heart_rate_bpm'' LIMIT 1000',
        'single_column_vital_type'
    );
    
    -- Test measurement_time index
    PERFORM test_index_performance(
        'patient_vitals',
        'measurement_time',
        'SELECT * FROM patient_vitals WHERE measurement_time >= NOW() - INTERVAL ''1 day''',
        'single_column_time'
    );
    
    -- Test 2: Composite index performance
    RAISE NOTICE '';
    RAISE NOTICE 'Test 2: Composite Indexes';
    
    -- Test patient_id + measurement_time composite
    PERFORM test_composite_index_performance(
        'patient_vitals',
        ARRAY['patient_id', 'measurement_time'],
        'SELECT * FROM patient_vitals WHERE patient_id = ''PATIENT_00001'' AND measurement_time >= NOW() - INTERVAL ''7 days''',
        'composite_patient_time'
    );
    
    -- Test vital_type + measurement_time composite
    PERFORM test_composite_index_performance(
        'patient_vitals',
        ARRAY['vital_type', 'measurement_time'],
        'SELECT vital_type, AVG(vital_value) FROM patient_vitals WHERE vital_type = ''heart_rate_bpm'' AND measurement_time >= NOW() - INTERVAL ''1 hour'' GROUP BY vital_type',
        'composite_vital_time'
    );
    
    -- Test 3: Partial index performance
    RAISE NOTICE '';
    RAISE NOTICE 'Test 3: Partial Indexes';
    
    -- Create and test partial index for alerts
    PERFORM test_partial_index_performance(
        'patient_vitals',
        'is_alert',
        'is_alert = true',
        'SELECT * FROM patient_vitals WHERE is_alert = true',
        'partial_alert_index'
    );
    
    -- Create and test partial index for recent data
    PERFORM test_partial_index_performance(
        'patient_vitals',
        'measurement_time',
        'measurement_time >= NOW() - INTERVAL ''30 days''',
        'SELECT * FROM patient_vitals WHERE measurement_time >= NOW() - INTERVAL ''7 days''',
        'partial_recent_data'
    );
    
    -- Test 4: Expression index performance
    RAISE NOTICE '';
    RAISE NOTICE 'Test 4: Expression Indexes';
    
    -- Test expression index on upper case patient_department
    PERFORM test_expression_index_performance(
        'patient_vitals',
        'UPPER(patient_department)',
        'CREATE INDEX IF NOT EXISTS idx_vitals_upper_dept ON patient_vitals(UPPER(patient_department))',
        'SELECT * FROM patient_vitals WHERE UPPER(patient_department) = ''ICU''',
        'expression_upper_dept'
    );
    
    -- Test expression index on date part
    PERFORM test_expression_index_performance(
        'patient_vitals',
        'EXTRACT(HOUR FROM measurement_time)',
        'CREATE INDEX IF NOT EXISTS idx_vitals_hour ON patient_vitals(EXTRACT(HOUR FROM measurement_time))',
        'SELECT COUNT(*) FROM patient_vitals WHERE EXTRACT(HOUR FROM measurement_time) BETWEEN 8 AND 18',
        'expression_hour'
    );
    
    -- 4. INDEX MAINTENANCE OVERHEAD
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 3: INDEX MAINTENANCE OVERHEAD';
    RAISE NOTICE '-------------------------------------';
    
    -- Test index maintenance overhead for INSERT operations
    RAISE NOTICE 'Testing INSERT overhead with different index configurations...';
    
    PERFORM test_index_maintenance_overhead(
        'patient_vitals',
        ARRAY['idx_vitals_patient_time', 'idx_vitals_measurement_time', 'idx_vitals_vital_type'],
        1000
    );
    
    -- Test index maintenance overhead for UPDATE operations
    PERFORM test_update_index_maintenance(
        'patient_vitals',
        'vital_value',
        ARRAY['idx_vitals_patient_time', 'idx_vitals_measurement_time'],
        500
    );
    
    -- Test index maintenance overhead for DELETE operations
    PERFORM test_delete_index_maintenance(
        'patient_vitals',
        ARRAY['idx_vitals_patient_time', 'idx_vitals_measurement_time'],
        200
    );
    
    -- 5. INDEX SELECTIVITY ANALYSIS
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 4: INDEX SELECTIVITY ANALYSIS';
    RAISE NOTICE '-------------------------------------';
    
    -- Analyze selectivity of different columns
    PERFORM analyze_index_selectivity('patient_vitals', 'patient_id');
    PERFORM analyze_index_selectivity('patient_vitals', 'vital_type');
    PERFORM analyze_index_selectivity('patient_vitals', 'patient_department');
    PERFORM analyze_index_selectivity('patient_vitals', 'device_id');
    PERFORM analyze_index_selectivity('patient_vitals', 'is_alert');
    
    -- 6. INDEX FRAGMENTATION ANALYSIS
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 5: INDEX FRAGMENTATION ANALYSIS';
    RAISE NOTICE '---------------------------------------';
    
    -- Check index fragmentation (requires pgstattuple)
    BEGIN
        PERFORM analyze_index_fragmentation('idx_vitals_patient_time');
        PERFORM analyze_index_fragmentation('idx_vitals_measurement_time');
        PERFORM analyze_index_fragmentation('idx_vitals_vital_type_time');
    EXCEPTION WHEN OTHERS THEN
        RAISE NOTICE 'Skipping fragmentation analysis: %', SQLERRM;
    END;
    
    -- 7. QUERY PLAN ANALYSIS WITH DIFFERENT INDEXES
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 6: QUERY PLAN ANALYSIS';
    RAISE NOTICE '------------------------------';
    
    -- Test common query patterns with different index configurations
    DECLARE
        test_queries TEXT[] := ARRAY[
            'SELECT patient_id, AVG(vital_value) FROM patient_vitals WHERE measurement_time >= NOW() - INTERVAL ''1 day'' AND vital_type = ''heart_rate_bpm'' GROUP BY patient_id HAVING AVG(vital_value) > 100',
            'SELECT patient_department, vital_type, COUNT(*), AVG(vital_value) FROM patient_vitals WHERE measurement_time >= NOW() - INTERVAL ''7 days'' GROUP BY patient_department, vital_type ORDER BY COUNT(*) DESC',
            'SELECT * FROM patient_vitals WHERE patient_id LIKE ''PATIENT_0%'' AND measurement_time BETWEEN NOW() - INTERVAL ''30 days'' AND NOW() - INTERVAL ''1 day'' ORDER BY measurement_time DESC LIMIT 100',
            'SELECT date_trunc(''hour'', measurement_time) as hour, COUNT(*) as readings, SUM(CASE WHEN is_alert THEN 1 ELSE 0 END) as alerts FROM patient_vitals WHERE measurement_time >= NOW() - INTERVAL ''24 hours'' GROUP BY date_trunc(''hour'', measurement_time) ORDER BY hour',
            'WITH ranked_vitals AS (SELECT *, ROW_NUMBER() OVER (PARTITION BY patient_id ORDER BY measurement_time DESC) as rn FROM patient_vitals) SELECT * FROM ranked_vitals WHERE rn = 1 AND is_alert = true'
        ];
        query_num INTEGER := 0;
    BEGIN
        FOREACH query_text IN ARRAY test_queries LOOP
            query_num := query_num + 1;
            RAISE NOTICE 'Query % analysis:', query_num;
            
            -- Test with all indexes
            PERFORM analyze_query_with_indexes(query_text, 'all_indexes', true);
            
            -- Test without indexes
            PERFORM analyze_query_with_indexes(query_text, 'no_indexes', false);
            
            -- Test with selective indexes only
            PERFORM analyze_query_with_selective_indexes(query_text);
        END LOOP;
    END;
    
    -- 8. INDEX RECOMMENDATIONS
    -- ============================================
    RAISE NOTICE '';
    RAISE NOTICE 'SECTION 7: INDEX RECOMMENDATIONS';
    RAISE NOTICE '--------------------------------';
    
    -- Generate index recommendations based on analysis
    PERFORM generate_index_recommendations();
    
    -- 9. SUMMARY AND REPORT
    -- ============================================
    analysis_end := clock_timestamp();
    
    RAISE NOTICE '';
    RAISE NOTICE '============================================';
    RAISE NOTICE 'INDEXING PERFORMANCE ANALYSIS SUMMARY';
    RAISE NOTICE '============================================';
    
    -- Display summary statistics
    DECLARE
        avg_improvement NUMERIC;
        best_index VARCHAR;
        worst_index VARCHAR;
        total_test_time NUMERIC;
    BEGIN
        -- Calculate average performance improvement
        SELECT 
            ROUND(AVG(performance_improvement), 2),
            ROUND(SUM(query_execution_time_ms) / 1000, 2)
        INTO avg_improvement, total_test_time
        FROM indexing_performance_results
        WHERE performance_improvement IS NOT NULL;
        
        -- Find best and worst performing indexes
        SELECT 
            index_name,
            table_name
        INTO best_index, worst_index
        FROM (
            SELECT 
                index_name,
                table_name,
                performance_improvement,
                ROW_NUMBER() OVER (ORDER BY performance_improvement DESC) as best_rank,
                ROW_NUMBER() OVER (ORDER BY performance_improvement ASC) as worst_rank
            FROM indexing_performance_results
            WHERE performance_improvement IS NOT NULL
              AND performance_improvement > 0
        ) ranked
        WHERE best_rank = 1 OR worst_rank = 1;
        
        RAISE NOTICE 'Analysis Results:';
        RAISE NOTICE '  Average performance improvement: %x', avg_improvement;
        RAISE NOTICE '  Best performing index: % on %', best_index, worst_index;
        RAISE NOTICE '  Total test execution time: % seconds', total_test_time;
        RAISE NOTICE '  Analysis duration: % seconds', 
            ROUND(EXTRACT(EPOCH FROM (analysis_end - analysis_start)), 2);
    END;
    
    -- Create summary view
    DROP VIEW IF EXISTS indexing_performance_summary;
    CREATE VIEW indexing_performance_summary AS
    SELECT 
        table_name,
        index_name,
        index_type,
        ROUND(index_size_mb, 2) as index_size_mb,
        ROUND(query_execution_time_ms, 3) as query_time_ms,
        ROUND(performance_improvement, 2) as performance_improvement_x,
        rows_returned,
        index_scans,
        is_used_regularly,
        ROUND(selectivity, 4) as selectivity,
        ROUND(maintenance_overhead_ms, 3) as maintenance_overhead_ms,
        recommendations
    FROM indexing_performance_results
    WHERE test_scenario NOT IN ('existing_index_analysis', 'index_recommendations')
    ORDER BY performance_improvement DESC NULLS LAST;
    
    RAISE NOTICE '';
    RAISE NOTICE 'Detailed analysis saved in: indexing_performance_results';
    RAISE NOTICE 'Summary view created: indexing_performance_summary';
    RAISE NOTICE '';
    RAISE NOTICE 'To view results:';
    RAISE NOTICE '  SELECT * FROM indexing_performance_summary ORDER BY performance_improvement_x DESC;';
    RAISE NOTICE '  SELECT * FROM indexing_performance_results WHERE test_scenario = ''index_recommendations'';';
    RAISE NOTICE '============================================';
    
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'Error during indexing analysis: %', SQLERRM;
        RAISE;
END $$;

-- ============================================
-- SUPPORTING FUNCTIONS
-- ============================================

-- Function to test single index performance
CREATE OR REPLACE FUNCTION test_index_performance(
    table_name VARCHAR,
    column_name VARCHAR,
    test_query TEXT,
    test_scenario VARCHAR
)
RETURNS VOID AS $$
DECLARE
    index_name VARCHAR := 'idx_test_' || column_name || '_' || 
        to_char(NOW(), 'YYYYMMDD_HH24MISS');
    create_index_sql TEXT;
    drop_index_sql TEXT;
    index_scan_time NUMERIC;
    seq_scan_time NUMERIC;
    performance_improvement NUMERIC;
    rows_returned BIGINT;
    explain_result JSONB;
    plan_data JSONB;
BEGIN
    RAISE NOTICE '  Testing index on column: %', column_name;
    
    -- Create test index
    create_index_sql := format(
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS %I ON %I(%I)',
        index_name, table_name, column_name
    );
    
    EXECUTE create_index_sql;
    
    -- Test with index (disable sequential scan)
    EXECUTE 'SET enable_seqscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    index_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000; -- Convert to ms
    rows_returned := (plan_data->>'Actual Rows')::BIGINT;
    
    -- Test without index (enable sequential scan, disable index scan)
    EXECUTE 'SET enable_seqscan = on';
    EXECUTE 'SET enable_indexscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    seq_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000; -- Convert to ms
    
    -- Calculate performance improvement
    IF seq_scan_time > 0 THEN
        performance_improvement := seq_scan_time / index_scan_time;
    ELSE
        performance_improvement := 1;
    END IF;
    
    -- Reset settings
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Get index size
    DECLARE
        index_size_mb NUMERIC;
    BEGIN
        SELECT pg_relation_size(index_name::regclass) / (1024.0 * 1024.0)
        INTO index_size_mb;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name, index_type,
            index_columns, index_size_mb, query_execution_time_ms,
            index_scan_time_ms, seq_scan_time_ms, performance_improvement,
            rows_returned, execution_plan
        ) VALUES (
            test_scenario, table_name, index_name, 'btree',
            column_name, index_size_mb, index_scan_time,
            index_scan_time, seq_scan_time, performance_improvement,
            rows_returned, explain_result
        );
    END;
    
    -- Drop test index
    drop_index_sql := format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXECUTE drop_index_sql;
    
    -- Output results
    RAISE NOTICE '    Index scan: % ms, Seq scan: % ms, Improvement: %x, Rows: %',
        ROUND(index_scan_time, 3), ROUND(seq_scan_time, 3),
        ROUND(performance_improvement, 2), rows_returned;
        
EXCEPTION WHEN OTHERS THEN
    -- Cleanup on error
    BEGIN
        EXECUTE format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
    
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error testing index: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to test composite index performance
CREATE OR REPLACE FUNCTION test_composite_index_performance(
    table_name VARCHAR,
    column_names VARCHAR[],
    test_query TEXT,
    test_scenario VARCHAR
)
RETURNS VOID AS $$
DECLARE
    index_name VARCHAR := 'idx_test_composite_' || 
        array_to_string(column_names, '_') || '_' ||
        to_char(NOW(), 'YYYYMMDD_HH24MISS');
    columns_list TEXT := array_to_string(column_names, ', ');
    create_index_sql TEXT;
    drop_index_sql TEXT;
    index_scan_time NUMERIC;
    seq_scan_time NUMERIC;
    performance_improvement NUMERIC;
    rows_returned BIGINT;
    explain_result JSONB;
    plan_data JSONB;
BEGIN
    RAISE NOTICE '  Testing composite index on columns: %', columns_list;
    
    -- Create test index
    create_index_sql := format(
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS %I ON %I(%s)',
        index_name, table_name, columns_list
    );
    
    EXECUTE create_index_sql;
    
    -- Test with index
    EXECUTE 'SET enable_seqscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    index_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    rows_returned := (plan_data->>'Actual Rows')::BIGINT;
    
    -- Test without index
    EXECUTE 'SET enable_seqscan = on';
    EXECUTE 'SET enable_indexscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    seq_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    
    -- Calculate performance improvement
    IF seq_scan_time > 0 THEN
        performance_improvement := seq_scan_time / index_scan_time;
    ELSE
        performance_improvement := 1;
    END IF;
    
    -- Reset settings
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Get index size
    DECLARE
        index_size_mb NUMERIC;
    BEGIN
        SELECT pg_relation_size(index_name::regclass) / (1024.0 * 1024.0)
        INTO index_size_mb;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name, index_type,
            index_columns, index_size_mb, query_execution_time_ms,
            index_scan_time_ms, seq_scan_time_ms, performance_improvement,
            rows_returned, execution_plan
        ) VALUES (
            test_scenario, table_name, index_name, 'btree',
            columns_list, index_size_mb, index_scan_time,
            index_scan_time, seq_scan_time, performance_improvement,
            rows_returned, explain_result
        );
    END;
    
    -- Drop test index
    drop_index_sql := format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXECUTE drop_index_sql;
    
    -- Output results
    RAISE NOTICE '    Index scan: % ms, Seq scan: % ms, Improvement: %x, Rows: %',
        ROUND(index_scan_time, 3), ROUND(seq_scan_time, 3),
        ROUND(performance_improvement, 2), rows_returned;
        
EXCEPTION WHEN OTHERS THEN
    -- Cleanup on error
    BEGIN
        EXECUTE format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
    
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error testing composite index: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to test partial index performance
CREATE OR REPLACE FUNCTION test_partial_index_performance(
    table_name VARCHAR,
    column_name VARCHAR,
    where_clause TEXT,
    test_query TEXT,
    test_scenario VARCHAR
)
RETURNS VOID AS $$
DECLARE
    index_name VARCHAR := 'idx_test_partial_' || column_name || '_' ||
        to_char(NOW(), 'YYYYMMDD_HH24MISS');
    create_index_sql TEXT;
    drop_index_sql TEXT;
    index_scan_time NUMERIC;
    seq_scan_time NUMERIC;
    performance_improvement NUMERIC;
    rows_returned BIGINT;
    explain_result JSONB;
    plan_data JSONB;
BEGIN
    RAISE NOTICE '  Testing partial index: % WHERE %', column_name, where_clause;
    
    -- Create partial index
    create_index_sql := format(
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS %I ON %I(%I) WHERE %s',
        index_name, table_name, column_name, where_clause
    );
    
    EXECUTE create_index_sql;
    
    -- Test with index
    EXECUTE 'SET enable_seqscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    index_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    rows_returned := (plan_data->>'Actual Rows')::BIGINT;
    
    -- Test without index
    EXECUTE 'SET enable_seqscan = on';
    EXECUTE 'SET enable_indexscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    seq_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    
    -- Calculate performance improvement
    IF seq_scan_time > 0 THEN
        performance_improvement := seq_scan_time / index_scan_time;
    ELSE
        performance_improvement := 1;
    END IF;
    
    -- Reset settings
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Get index size
    DECLARE
        index_size_mb NUMERIC;
    BEGIN
        SELECT pg_relation_size(index_name::regclass) / (1024.0 * 1024.0)
        INTO index_size_mb;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name, index_type,
            index_columns, index_size_mb, query_execution_time_ms,
            index_scan_time_ms, seq_scan_time_ms, performance_improvement,
            rows_returned, execution_plan
        ) VALUES (
            test_scenario, table_name, index_name, 'btree_partial',
            column_name || ' WHERE ' || where_clause, index_size_mb, index_scan_time,
            index_scan_time, seq_scan_time, performance_improvement,
            rows_returned, explain_result
        );
    END;
    
    -- Drop test index
    drop_index_sql := format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXECUTE drop_index_sql;
    
    -- Output results
    RAISE NOTICE '    Index scan: % ms, Seq scan: % ms, Improvement: %x, Rows: %',
        ROUND(index_scan_time, 3), ROUND(seq_scan_time, 3),
        ROUND(performance_improvement, 2), rows_returned;
        
EXCEPTION WHEN OTHERS THEN
    -- Cleanup on error
    BEGIN
        EXECUTE format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
    
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error testing partial index: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to test expression index performance
CREATE OR REPLACE FUNCTION test_expression_index_performance(
    table_name VARCHAR,
    expression TEXT,
    create_index_sql TEXT,
    test_query TEXT,
    test_scenario VARCHAR
)
RETURNS VOID AS $$
DECLARE
    index_name VARCHAR;
    drop_index_sql TEXT;
    index_scan_time NUMERIC;
    seq_scan_time NUMERIC;
    performance_improvement NUMERIC;
    rows_returned BIGINT;
    explain_result JSONB;
    plan_data JSONB;
BEGIN
    RAISE NOTICE '  Testing expression index: %', expression;
    
    -- Create expression index
    EXECUTE create_index_sql;
    
    -- Extract index name from create statement
    index_name := substring(create_index_sql from 'INDEX.*?ON.*?\s+(\w+)\s*\(');
    
    -- Test with index
    EXECUTE 'SET enable_seqscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    index_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    rows_returned := (plan_data->>'Actual Rows')::BIGINT;
    
    -- Test without index
    EXECUTE 'SET enable_seqscan = on';
    EXECUTE 'SET enable_indexscan = off';
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', test_query)
    INTO explain_result;
    
    plan_data := explain_result->0->'Plan';
    seq_scan_time := (plan_data->>'Actual Total Time')::NUMERIC * 1000;
    
    -- Calculate performance improvement
    IF seq_scan_time > 0 THEN
        performance_improvement := seq_scan_time / index_scan_time;
    ELSE
        performance_improvement := 1;
    END IF;
    
    -- Reset settings
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Get index size
    DECLARE
        index_size_mb NUMERIC;
    BEGIN
        SELECT pg_relation_size(index_name::regclass) / (1024.0 * 1024.0)
        INTO index_size_mb;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name, index_type,
            index_columns, index_size_mb, query_execution_time_ms,
            index_scan_time_ms, seq_scan_time_ms, performance_improvement,
            rows_returned, execution_plan
        ) VALUES (
            test_scenario, table_name, index_name, 'btree_expression',
            expression, index_size_mb, index_scan_time,
            index_scan_time, seq_scan_time, performance_improvement,
            rows_returned, explain_result
        );
    END;
    
    -- Drop test index
    drop_index_sql := format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXECUTE drop_index_sql;
    
    -- Output results
    RAISE NOTICE '    Index scan: % ms, Seq scan: % ms, Improvement: %x, Rows: %',
        ROUND(index_scan_time, 3), ROUND(seq_scan_time, 3),
        ROUND(performance_improvement, 2), rows_returned;
        
EXCEPTION WHEN OTHERS THEN
    -- Cleanup on error
    BEGIN
        EXECUTE format('DROP INDEX CONCURRENTLY IF EXISTS %I', index_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
    
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error testing expression index: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to test index maintenance overhead for INSERT
CREATE OR REPLACE FUNCTION test_index_maintenance_overhead(
    table_name VARCHAR,
    index_names VARCHAR[],
    insert_count INTEGER
)
RETURNS VOID AS $$
DECLARE
    index_name VARCHAR;
    temp_table_name VARCHAR := 'test_insert_data_' || 
        to_char(NOW(), 'YYYYMMDD_HH24MISS');
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    with_index_time NUMERIC;
    without_index_time NUMERIC;
    overhead_percentage NUMERIC;
    i INTEGER;
BEGIN
    RAISE NOTICE '  Testing INSERT overhead with % indexes on % rows', 
        array_length(index_names, 1), insert_count;
    
    -- Create temporary table with same structure
    EXECUTE format('CREATE TEMP TABLE %I (LIKE %I)', 
        temp_table_name, table_name);
    
    -- Generate test data
    EXECUTE format('
        INSERT INTO %I 
        SELECT 
            ''TEST_PATIENT_'' || generate_series,
            NOW() - (random() * INTERVAL ''365 days''),
            CASE (random() * 5)::INT
                WHEN 0 THEN ''heart_rate_bpm''
                WHEN 1 THEN ''blood_pressure_systolic''
                WHEN 2 THEN ''blood_pressure_diastolic''
                WHEN 3 THEN ''temperature_celsius''
                WHEN 4 THEN ''oxygen_saturation''
                ELSE ''respiratory_rate''
            END,
            50 + (random() * 150),
            random() > 0.95,
            CASE (random() * 3)::INT
                WHEN 0 THEN ''ICU''
                WHEN 1 THEN ''WARD''
                WHEN 2 THEN ''OUTPATIENT''
                ELSE ''EMERGENCY''
            END,
            ''DEVICE_'' || (random() * 1000)::INT,
            CASE (random() * 4)::INT
                WHEN 0 THEN ''PUBLIC''
                WHEN 1 THEN ''INTERNAL''
                WHEN 2 THEN ''CONFIDENTIAL''
                ELSE ''RESTRICTED''
            END
        FROM generate_series(1, %s)',
        temp_table_name, insert_count
    );
    
    -- Test with all indexes
    start_time := clock_timestamp();
    
    EXECUTE format('
        INSERT INTO %I 
        SELECT * FROM %I',
        table_name, temp_table_name
    );
    
    end_time := clock_timestamp();
    with_index_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    -- Delete test data
    EXECUTE format('
        DELETE FROM %I 
        WHERE patient_id LIKE ''TEST_PATIENT_%%''',
        table_name
    );
    
    -- Disable indexes temporarily (not directly possible, so we'll simulate)
    -- Instead, we'll drop and recreate indexes
    FOREACH index_name IN ARRAY index_names LOOP
        BEGIN
            EXECUTE format('DROP INDEX CONCURRENTLY %I', index_name);
        EXCEPTION WHEN OTHERS THEN
            RAISE NOTICE '    Could not drop index %: %', index_name, SQLERRM;
        END;
    END LOOP;
    
    -- Test without indexes
    start_time := clock_timestamp();
    
    EXECUTE format('
        INSERT INTO %I 
        SELECT * FROM %I',
        table_name, temp_table_name
    );
    
    end_time := clock_timestamp();
    without_index_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    -- Delete test data again
    EXECUTE format('
        DELETE FROM %I 
        WHERE patient_id LIKE ''TEST_PATIENT_%%''',
        table_name
    );
    
    -- Recreate indexes
    FOREACH index_name IN ARRAY index_names LOOP
        BEGIN
            -- Note: In real scenario, we would need the original CREATE INDEX statements
            -- For this test, we'll just note that indexes need to be recreated
            RAISE NOTICE '    Note: Index % needs to be recreated', index_name;
        EXCEPTION WHEN OTHERS THEN
            NULL;
        END;
    END LOOP;
    
    -- Calculate overhead
    IF without_index_time > 0 THEN
        overhead_percentage := ((with_index_time - without_index_time) / 
                               without_index_time) * 100;
    ELSE
        overhead_percentage := 0;
    END IF;
    
    -- Store results
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, index_name,
        maintenance_overhead_ms, rows_returned,
        recommendations
    ) VALUES (
        'index_maintenance_insert',
        table_name,
        array_to_string(index_names, ', '),
        with_index_time - without_index_time,
        insert_count,
        format('Index maintenance overhead: %s%% per insert', 
               ROUND(overhead_percentage / insert_count, 3))
    );
    
    -- Cleanup
    EXECUTE format('DROP TABLE %I', temp_table_name);
    
    -- Output results
    RAISE NOTICE '    With indexes: % ms, Without: % ms, Overhead: % ms (%%)',
        ROUND(with_index_time, 3), ROUND(without_index_time, 3),
        ROUND(with_index_time - without_index_time, 3),
        ROUND(overhead_percentage, 2);
        
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE '    Error testing index maintenance: %', SQLERRM;
    
    -- Cleanup
    BEGIN
        EXECUTE format('DROP TABLE IF EXISTS %I', temp_table_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
END;
$$ LANGUAGE plpgsql;

-- Function to test index maintenance overhead for UPDATE
CREATE OR REPLACE FUNCTION test_update_index_maintenance(
    table_name VARCHAR,
    update_column VARCHAR,
    index_names VARCHAR[],
    update_count INTEGER
)
RETURNS VOID AS $$
DECLARE
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    with_index_time NUMERIC;
    without_index_time NUMERIC;
    overhead_percentage NUMERIC;
BEGIN
    RAISE NOTICE '  Testing UPDATE overhead on column: %', update_column;
    
    -- Create test data for updates
    EXECUTE format('
        UPDATE %I 
        SET %I = vital_value * 1.1 
        WHERE ctid IN (
            SELECT ctid 
            FROM %I 
            WHERE vital_type = ''heart_rate_bpm''
            LIMIT %s
        )',
        table_name, update_column, table_name, update_count
    );
    
    -- Store time (with indexes)
    start_time := clock_timestamp();
    
    -- Execute update
    EXECUTE format('
        UPDATE %I 
        SET %I = vital_value * 0.9 
        WHERE ctid IN (
            SELECT ctid 
            FROM %I 
            WHERE vital_type = ''heart_rate_bpm''
            LIMIT %s
        )',
        table_name, update_column, table_name, update_count
    );
    
    end_time := clock_timestamp();
    with_index_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    -- Reset data
    EXECUTE format('
        UPDATE %I 
        SET %I = vital_value / 0.9 
        WHERE ctid IN (
            SELECT ctid 
            FROM %I 
            WHERE vital_type = ''heart_rate_bpm''
            LIMIT %s
        )',
        table_name, update_column, table_name, update_count
    );
    
    -- Since we can't easily disable indexes for UPDATE, we'll estimate
    -- based on the number of indexes and updated columns
    DECLARE
        total_indexes INTEGER := array_length(index_names, 1);
        estimated_overhead_ms NUMERIC;
    BEGIN
        -- Rough estimate: 0.1ms per index per 100 updates
        estimated_overhead_ms := total_indexes * (update_count / 100.0) * 0.1;
        without_index_time := with_index_time - estimated_overhead_ms;
        
        IF without_index_time > 0 THEN
            overhead_percentage := (estimated_overhead_ms / without_index_time) * 100;
        ELSE
            overhead_percentage := 0;
        END IF;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name,
            maintenance_overhead_ms, rows_returned,
            recommendations
        ) VALUES (
            'index_maintenance_update',
            table_name,
            array_to_string(index_names, ', '),
            estimated_overhead_ms,
            update_count,
            format('Estimated update overhead: %s ms per 100 rows (%s indexes)',
                   ROUND(estimated_overhead_ms / (update_count / 100.0), 3),
                   total_indexes)
        );
        
        -- Output results
        RAISE NOTICE '    Estimated with indexes: % ms, Without: % ms, Overhead: % ms (%%)',
            ROUND(with_index_time, 3), ROUND(without_index_time, 3),
            ROUND(estimated_overhead_ms, 3), ROUND(overhead_percentage, 2);
    END;
    
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE '    Error testing update maintenance: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to test index maintenance overhead for DELETE
CREATE OR REPLACE FUNCTION test_delete_index_maintenance(
    table_name VARCHAR,
    index_names VARCHAR[],
    delete_count INTEGER
)
RETURNS VOID AS $$
DECLARE
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    with_index_time NUMERIC;
    without_index_time NUMERIC;
    overhead_percentage NUMERIC;
    temp_table_name VARCHAR := 'temp_backup_' || 
        to_char(NOW(), 'YYYYMMDD_HH24MISS');
BEGIN
    RAISE NOTICE '  Testing DELETE overhead';
    
    -- Backup data that will be deleted
    EXECUTE format('
        CREATE TEMP TABLE %I AS 
        SELECT * FROM %I 
        WHERE vital_type = ''heart_rate_bpm''
        LIMIT %s',
        temp_table_name, table_name, delete_count
    );
    
    -- Test with indexes
    start_time := clock_timestamp();
    
    EXECUTE format('
        DELETE FROM %I 
        WHERE ctid IN (
            SELECT ctid 
            FROM %I 
            LIMIT %s
        )',
        table_name, temp_table_name, delete_count
    );
    
    end_time := clock_timestamp();
    with_index_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    -- Restore deleted data
    EXECUTE format('
        INSERT INTO %I 
        SELECT * FROM %I',
        table_name, temp_table_name
    );
    
    -- Estimate without indexes (similar to UPDATE)
    DECLARE
        total_indexes INTEGER := array_length(index_names, 1);
        estimated_overhead_ms NUMERIC;
    BEGIN
        -- Rough estimate: 0.15ms per index per 100 deletes
        estimated_overhead_ms := total_indexes * (delete_count / 100.0) * 0.15;
        without_index_time := with_index_time - estimated_overhead_ms;
        
        IF without_index_time > 0 THEN
            overhead_percentage := (estimated_overhead_ms / without_index_time) * 100;
        ELSE
            overhead_percentage := 0;
        END IF;
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name,
            maintenance_overhead_ms, rows_returned,
            recommendations
        ) VALUES (
            'index_maintenance_delete',
            table_name,
            array_to_string(index_names, ', '),
            estimated_overhead_ms,
            delete_count,
            format('Estimated delete overhead: %s ms per 100 rows (%s indexes)',
                   ROUND(estimated_overhead_ms / (delete_count / 100.0), 3),
                   total_indexes)
        );
        
        -- Output results
        RAISE NOTICE '    Estimated with indexes: % ms, Without: % ms, Overhead: % ms (%%)',
            ROUND(with_index_time, 3), ROUND(without_index_time, 3),
            ROUND(estimated_overhead_ms, 3), ROUND(overhead_percentage, 2);
    END;
    
    -- Cleanup
    EXECUTE format('DROP TABLE %I', temp_table_name);
    
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE '    Error testing delete maintenance: %', SQLERRM;
    
    -- Cleanup
    BEGIN
        EXECUTE format('DROP TABLE IF EXISTS %I', temp_table_name);
    EXCEPTION WHEN OTHERS THEN
        NULL;
    END;
END;
$$ LANGUAGE plpgsql;

-- Function to analyze index selectivity
CREATE OR REPLACE FUNCTION analyze_index_selectivity(
    table_name VARCHAR,
    column_name VARCHAR
)
RETURNS VOID AS $$
DECLARE
    total_rows BIGINT;
    distinct_values BIGINT;
    selectivity NUMERIC;
    most_common_vals TEXT[];
    most_common_freqs NUMERIC[];
    histogram_bounds TEXT[];
    correlation NUMERIC;
BEGIN
    -- Get column statistics
    EXECUTE format('
        SELECT 
            n_distinct,
            most_common_vals::TEXT[],
            most_common_freqs::NUMERIC[],
            histogram_bounds::TEXT[],
            correlation
        FROM pg_stats 
        WHERE tablename = %L 
          AND attname = %L',
        table_name, column_name
    ) INTO distinct_values, most_common_vals, most_common_freqs, 
         histogram_bounds, correlation;
    
    -- Get total rows
    EXECUTE format('
        SELECT COUNT(*) 
        FROM %I',
        table_name
    ) INTO total_rows;
    
    -- Calculate selectivity
    IF distinct_values > 0 THEN
        selectivity := 1.0 / distinct_values;
    ELSE
        selectivity := 0;
    END IF;
    
    -- Store results
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, index_name,
        index_columns, selectivity,
        recommendations
    ) VALUES (
        'index_selectivity',
        table_name,
        'N/A',
        column_name,
        selectivity,
        format('Selectivity: %s, Distinct values: %s, Correlation: %s',
               ROUND(selectivity, 4), distinct_values, ROUND(correlation, 4))
    );
    
    -- Output results
    RAISE NOTICE '    Column %: selectivity=%, distinct=%', 
        column_name, ROUND(selectivity, 4), distinct_values;
        
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE '    Error analyzing selectivity for %: %', 
        column_name, SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to analyze index fragmentation
CREATE OR REPLACE FUNCTION analyze_index_fragmentation(
    index_name VARCHAR
)
RETURNS VOID AS $$
DECLARE
    fragmentation_stats RECORD;
    fragmentation_percentage NUMERIC;
BEGIN
    -- Get index fragmentation stats using pgstattuple
    EXECUTE format('SELECT * FROM pgstatindex(%L)', index_name)
    INTO fragmentation_stats;
    
    -- Calculate fragmentation percentage
    IF fragmentation_stats.leaf_pages > 0 THEN
        fragmentation_percentage := 
            (fragmentation_stats.deleted_pages::NUMERIC / 
             fragmentation_stats.leaf_pages) * 100;
    ELSE
        fragmentation_percentage := 0;
    END IF;
    
    -- Store results
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, index_name,
        index_size_updates, -- using this column for deleted pages
        recommendations
    ) VALUES (
        'index_fragmentation',
        (SELECT tablename FROM pg_indexes WHERE indexname = analyze_index_fragmentation.index_name),
        index_name,
        fragmentation_stats.deleted_pages,
        format('Fragmentation: %s%%, Leaf pages: %s, Deleted pages: %s',
               ROUND(fragmentation_percentage, 2),
               fragmentation_stats.leaf_pages,
               fragmentation_stats.deleted_pages)
    );
    
    -- Output results
    RAISE NOTICE '    Index %: fragmentation=%%, leaf pages=%, deleted pages=%', 
        index_name, ROUND(fragmentation_percentage, 2),
        fragmentation_stats.leaf_pages,
        fragmentation_stats.deleted_pages;
        
EXCEPTION WHEN OTHERS THEN
    RAISE NOTICE '    Error analyzing fragmentation for %: %', 
        index_name, SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to analyze query with different index configurations
CREATE OR REPLACE FUNCTION analyze_query_with_indexes(
    query_text TEXT,
    config_name VARCHAR,
    use_indexes BOOLEAN
)
RETURNS VOID AS $$
DECLARE
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    execution_time NUMERIC;
    explain_result JSONB;
    plan_data JSONB;
    rows_returned BIGINT;
    plan_text TEXT;
BEGIN
    -- Set configuration
    IF use_indexes THEN
        EXECUTE 'SET enable_seqscan = off';
        EXECUTE 'SET enable_indexscan = on';
    ELSE
        EXECUTE 'SET enable_seqscan = on';
        EXECUTE 'SET enable_indexscan = off';
    END IF;
    
    -- Execute with timing
    start_time := clock_timestamp();
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', query_text)
    INTO explain_result;
    
    end_time := clock_timestamp();
    execution_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    plan_data := explain_result->0->'Plan';
    rows_returned := (plan_data->>'Actual Rows')::BIGINT;
    
    -- Get plan as text for analysis
    EXECUTE format('EXPLAIN %s', query_text) INTO plan_text;
    
    -- Reset configuration
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Store results
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, index_name,
        query_execution_time_ms, rows_returned,
        recommendations, execution_plan
    ) VALUES (
        'query_plan_analysis',
        'multiple',
        config_name,
        execution_time,
        rows_returned,
        substring(query_text from 1 for 100) || '...',
        explain_result
    );
    
    -- Output results
    RAISE NOTICE '    Config %: % ms, Rows: %',
        config_name, ROUND(execution_time, 3), rows_returned;
        
EXCEPTION WHEN OTHERS THEN
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error analyzing query: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Function to analyze query with selective indexes
CREATE OR REPLACE FUNCTION analyze_query_with_selective_indexes(query_text TEXT)
RETURNS VOID AS $$
DECLARE
    -- This is a simplified version - in production, you would
    -- analyze the query and determine which indexes would be most beneficial
    start_time TIMESTAMPTZ;
    end_time TIMESTAMPTZ;
    execution_time NUMERIC;
    explain_result JSONB;
BEGIN
    -- For this example, we'll just run the query and see what indexes are used
    EXECUTE 'SET enable_seqscan = on';
    EXECUTE 'SET enable_indexscan = on';
    
    start_time := clock_timestamp();
    
    EXECUTE format('EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) %s', query_text)
    INTO explain_result;
    
    end_time := clock_timestamp();
    execution_time := EXTRACT(EPOCH FROM (end_time - start_time)) * 1000;
    
    -- Reset configuration
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    -- Extract index usage from plan
    DECLARE
        used_indexes TEXT[];
        plan_node JSONB := explain_result->0->'Plan';
    BEGIN
        used_indexes := find_used_indexes(plan_node);
        
        -- Store results
        INSERT INTO indexing_performance_results (
            test_scenario, table_name, index_name,
            query_execution_time_ms,
            recommendations
        ) VALUES (
            'selective_index_analysis',
            'multiple',
            array_to_string(used_indexes, ', '),
            execution_time,
            format('Query used indexes: %s', array_to_string(used_indexes, ', '))
        );
        
        -- Output results
        RAISE NOTICE '    Used indexes: %', array_to_string(used_indexes, ', ');
    END;
    
EXCEPTION WHEN OTHERS THEN
    EXECUTE 'RESET enable_seqscan';
    EXECUTE 'RESET enable_indexscan';
    
    RAISE NOTICE '    Error in selective index analysis: %', SQLERRM;
END;
$$ LANGUAGE plpgsql;

-- Helper function to find used indexes in execution plan
CREATE OR REPLACE FUNCTION find_used_indexes(plan_node JSONB)
RETURNS TEXT[] AS $$
DECLARE
    indexes TEXT[] := '{}';
    child JSONB;
BEGIN
    -- Check current node
    IF plan_node->>'Node Type' IN ('Index Scan', 'Index Only Scan') THEN
        IF plan_node ? 'Index Name' THEN
            indexes := indexes || ARRAY[plan_node->>'Index Name'];
        END IF;
    END IF;
    
    -- Recursively check children
    IF plan_node ? 'Plans' THEN
        FOR child IN SELECT * FROM jsonb_array_elements(plan_node->'Plans') LOOP
            indexes := indexes || find_used_indexes(child);
        END LOOP;
    END IF;
    
    RETURN indexes;
END;
$$ LANGUAGE plpgsql;

-- Function to generate index recommendations
CREATE OR REPLACE FUNCTION generate_index_recommendations()
RETURNS VOID AS $$
DECLARE
    recommendations TEXT := '';
BEGIN
    -- Generate recommendations based on analysis
    
    -- 1. Recommendations from existing index analysis
    SELECT recommendations || 
        '1. UNUSED INDEXES:' || E'\n' ||
        string_agg(
            '    Consider dropping: ' || index_name || 
            ' on ' || table_name || 
            ' (' || ROUND(index_size_mb, 2) || ' MB, ' || 
            index_scans || ' scans)',
            E'\n'
        ) || E'\n\n'
    INTO recommendations
    FROM indexing_performance_results
    WHERE test_scenario = 'existing_index_analysis'
      AND index_size_mb > 10
      AND index_scans < 10
      AND is_used_regularly = false;
    
    -- 2. Recommendations from performance tests
    SELECT recommendations ||
        '2. HIGH-PERFORMANCE INDEXES:' || E'\n' ||
        string_agg(
            '    Keep and maintain: ' || index_name || 
            ' (' || ROUND(performance_improvement, 2) || 'x improvement)',
            E'\n'
        ) || E'\n\n'
    INTO recommendations
    FROM indexing_performance_results
    WHERE performance_improvement > 10
    ORDER BY performance_improvement DESC
    LIMIT 5;
    
    -- 3. Recommendations for new indexes
    SELECT recommendations ||
        '3. POTENTIAL NEW INDEXES:' || E'\n' ||
        '    Composite index on (patient_department, measurement_time)' || E'\n' ||
        '    Partial index for is_alert = true' || E'\n' ||
        '    Expression index on date_trunc(''hour'', measurement_time)' || E'\n\n'
    INTO recommendations;
    
    -- 4. Maintenance recommendations
    SELECT recommendations ||
        '4. INDEX MAINTENANCE:' || E'\n' ||
        '    Monitor index fragmentation monthly' || E'\n' ||
        '    Reindex large indexes quarterly' || E'\n' ||
        '    Update statistics weekly' || E'\n\n'
    INTO recommendations;
    
    -- 5. General best practices
    recommendations := recommendations ||
        '5. BEST PRACTICES:' || E'\n' ||
        '    Create indexes based on query patterns, not just columns' || E'\n' ||
        '    Use partial indexes for filtered queries' || E'\n' ||
        '    Consider covering indexes for frequent queries' || E'\n' ||
        '    Monitor index usage and adjust as needed';
    
    -- Store recommendations
    INSERT INTO indexing_performance_results (
        test_scenario, table_name, recommendations
    ) VALUES (
        'index_recommendations',
        'all',
        recommendations
    );
    
    -- Output recommendations
    RAISE NOTICE 'Index Recommendations Generated:';
    RAISE NOTICE '%', recommendations;
    
END;
$$ LANGUAGE plpgsql;

-- Create monitoring view for index performance
CREATE OR REPLACE VIEW index_performance_monitor AS
SELECT 
    table_name,
    index_name,
    ROUND(index_size_mb, 2) as index_size_mb,
    ROUND(query_execution_time_ms, 3) as last_query_time_ms,
    ROUND(performance_improvement, 2) as performance_improvement_x,
    index_scans,
    is_used_regularly,
    ROUND(selectivity, 4) as selectivity,
    ROUND(maintenance_overhead_ms, 3) as maintenance_overhead_ms_per_100_rows,
    CASE 
        WHEN performance_improvement > 20 THEN ' Excellent'
        WHEN performance_improvement > 5 THEN ' Good'
        WHEN performance_improvement > 1 THEN ' Moderate'
        ELSE ' Poor'
    END as performance_rating,
    CASE 
        WHEN index_scans < 10 AND index_size_mb > 10 THEN ' Consider dropping'
        WHEN index_scans < 100 AND index_size_mb > 50 THEN ' Monitor usage'
        ELSE ' Actively used'
    END as usage_rating
FROM indexing_performance_results
WHERE test_scenario NOT IN ('existing_index_analysis', 'index_recommendations')
ORDER BY index_size_mb DESC;

-- Create function to generate index creation SQL
CREATE OR REPLACE FUNCTION generate_index_creation_sql()
RETURNS TEXT AS $$
DECLARE
    index_sql TEXT := '';
BEGIN
    -- Generate SQL for recommended indexes
    SELECT index_sql ||
        '-- Recommended indexes based on analysis' || E'\n\n' ||
        '-- 1. Composite index for patient queries' || E'\n' ||
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_vitals_patient_dept_time ' ||
        'ON patient_vitals(patient_id, patient_department, measurement_time);' || E'\n\n' ||
        '-- 2. Partial index for alerts' || E'\n' ||
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_vitals_alerts ' ||
        'ON patient_vitals(measurement_time) WHERE is_alert = true;' || E'\n\n' ||
        '-- 3. Expression index for hourly aggregation' || E'\n' ||
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_vitals_hourly ' ||
        'ON patient_vitals(date_trunc(''hour'', measurement_time), vital_type);' || E'\n\n' ||
        '-- 4. Covering index for common reports' || E'\n' ||
        'CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_vitals_reports ' ||
        'ON patient_vitals(patient_department, measurement_time) ' ||
        'INCLUDE (vital_type, vital_value, is_alert);'
    INTO index_sql;
    
    RETURN index_sql;
END;
$$ LANGUAGE plpgsql;

-- Final cleanup and output
\timing off

RAISE NOTICE '';
RAISE NOTICE '============================================';
RAISE NOTICE 'ADDITIONAL UTILITIES AVAILABLE:';
RAISE NOTICE '============================================';
RAISE NOTICE '1. Monitor index performance:';
RAISE NOTICE '   SELECT * FROM index_performance_monitor;';
RAISE NOTICE '';
RAISE NOTICE '2. Generate index creation SQL:';
RAISE NOTICE '   SELECT generate_index_creation_sql();';
RAISE NOTICE '';
RAISE NOTICE '3. Check for unused indexes:';
RAISE NOTICE '   SELECT table_name, index_name, index_size_mb, index_scans';
RAISE NOTICE '   FROM indexing_performance_results';
RAISE NOTICE '   WHERE test_scenario = ''existing_index_analysis''';
RAISE NOTICE '     AND index_scans < 10';
RAISE NOTICE '     AND index_size_mb > 10';
RAISE NOTICE '   ORDER BY index_size_mb DESC;';
RAISE NOTICE '';
RAISE NOTICE '4. Get top performing indexes:';
RAISE NOTICE '   SELECT index_name, performance_improvement_x, query_time_ms';
RAISE NOTICE '   FROM indexing_performance_summary';
RAISE NOTICE '   WHERE performance_improvement_x > 5';
RAISE NOTICE '   ORDER BY performance_improvement_x DESC;';
RAISE NOTICE '============================================';